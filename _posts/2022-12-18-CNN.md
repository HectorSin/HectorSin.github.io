---
layout: posts
title: "신경망부흥의시작CNN"
categories: ML
tag: [python, ML, Concept]
toc: true
---

# 합성곱 신경망 CNN(Convolutional Neural Network)

***

> <참고> https://www.youtube.com/watch?v=YRhxdVk_sIs
> <참고> course.fast.ai/lessons/lesson4.html

## 1. 시각 정보 처리와 합성곱의 필요성

***

### 합성곱 신경망(Convolutional Neural Network-CNN)

- 이미지 분석 정확도를 획기적으로 개선하며 신경망 분야의 새로운 도약을 이끔
- 합성곱은 동물이 시각 정보가 들어올 경우 시각 피질에 있는 뉴런들이 시야의 일부 **범위 안에 있는 영역에 대해 활성화되어 정보를 받아들인다**는 실험의 결과로 알게된 방식을 이미지 인식에 적용한것
- 시각 수용장의 역할을 **합성곱** 혹은 **컨볼루션(Convolution)**이라는 연산이 수행해 결과가 신경세포로 전달
- 다른 알고리즘에 비해 **입력에 대한 전처리가 거의 필요 없음**
- CNN은 입력 틍징 추출하는 방법도 함께 학습되므로 관련 지식을 바탕으로 **특징 추출해 내는 과정(Feature Engineering)**이 필요하지 않으며 이것이 주 장점
- 기존 신경망은 이미지가 가진 기하적 관계를 유지하지 못해 유의미한 데이터를 얻지 못했다.
- 이미지 처리 분야에서 특정한 영역 내에 있는 모든 **픽셀**정보로 하나의 값을 생성하는 일을 합성곱이라고 함
- 합성곱은 특정한 영역을 하나의 특징으로 변환하는 역할을 하며 합성곱과 함께 현재는 **풀링(Pooling)**이라고 부르는 **서브샘플링 계층**을 도입.

## 2. 합성곱의 기본 개념 이해

***

- 이미지를 조작할 때 사용하는 방법 중에 커널(Kernel) 혹은 **필터(Filter)**라고 불리는 작은 행렬을 사용하여 새로운 값을 얻는 방법이 있음
- 필터와 원본 이미지의 대응되는 값들을 서로 곱한 뒤에 모두 더하여 새로운 이미지의 픽셀값 p를 구하는 것, 이러한 연산을 합성곱 연산, 혹은 컨볼루션이라 함
- **평균 필터** & **상자 필터**
  > 특정 픽셀 주변의 픽셀 들이 가진 값의 평균을 취하는 필터
- **가우스 필터**
  > 필터 영역의 모든 픽셀에 동일 한 중요성을 부여하는 것이 아닌 중심 픽엘에는 더 높은 중요도를 부여하고, 중심에서 멀어질 수록 중요성을 낮게함
  >
  > - 여기서 중요도를 **가중치(Weight)**라고 부르고 가우스 함수를 통해 그 값을 결정
  > - 가우스 함수는 종 모양 함수 혹은 정규 분포 함수 모양을 띔

## 3. 합성곱을 통한 특징 추출

***

- 윤곽선을 찾는 것은 색이 연속적이지 않고 갑작스럽게 변하는 픽셀들을 찾아내는 것
- 픽셀의 위치를 **정의역** / 픽셀의 색상을 **치역**으로 하는 함수
  > 픽셀의 각 지점마다 색상 값이 변하는 방향으로 기울기를 구할 수 있음
- 기울기를 구하는 **델 연산자** / 값이 크게 변하는 곳인 기울기 벡터의 크기가 커지는 지점 감지를 위해 사용하는 **라플라시안(Laplacian)**연산 적용
- 두번 이상 미분할 수 있는 함수 f가 있을 때 라플라시안 연산 사용
  > 기울기 연산으로 얻은 값을 자기 자신과 **내적**하는 연산으로 기울기 벡터의 크기를 의미로 변화가 큰 **윤곽선 지점**에서 큰 값
- 합성곱 연산을 할 때 필터로 사용되는 행렬만 바꾸면 여러 가지 다른 결과를 얻을 수 있음
  > 원본 이미지에서 필터의 크기와 동일한 크기를 가진 부분 영역에 대해 해당 필터가 원하는 특징을 얻어내는 것
- 이것을 설계 안하고 기계가 스스로 좋은 필터를 만들어낸다면? -> 필터의 가중치를 모델의 파라미터로 만드는 일
  > 합성곱 신경망의 기본 아이디어

## 4. 합성곱 수행 신경망의 기본 구조와 문제

***

- 하나의 필터만으로는 이미지의 특징을 다양하게 추출할 수 없음
- 특성맵
  > 하나의 이미지에 n개의 필터를 가진 모델의 파라미터로 두고 학습을 진행하여 n장의 특징 추출 결과를 얻는 것
  > 이미지를 처리하고 얻는 결과는 이미지
  > 이 이미지에 대해 다시 합성곱을 수행하는 계층을 계속해서 이어나갈 수 있지만 이때 **문제가 발생**
- **문제**
  > 합성곱을 적용하면 이미지가 작아진다
  > 합성곱을 거치며 작아진 이미지가 이미지 전체의 특성을 요약한 것이 아님
  > 이미지의 가장자리 정보들이 소실되고 중심부의 정보만 살아남는 것이기에 정보를 추상화 시키는 과정도 아님
  > 정보를 요약하지 않으면 입력 단계의 작은 잡음이 가진 영향력도 계층을 거치며 사라지지 않고 계속 전파
- **결론**
  > 합성곱에 의해 이미지가 작아지는 것이 아니고, **정보를 요약하는 계층을 통해 이미지를 적절한 크기로 줄이는 과정이 필요**
  > 이러한 일을 **풀링(Pooling)**이라는 기법을 통해 이루어짐

## 5. 패딩, 스트라이딩, 다중 채널

***

### **패딩**
- 합성곱 연산을 사용하면 이미지의 크기가 작아짐
> 이를 방지하기 위해 입력 이미지의 주변에 값을 덧대어 채워주는 일을 **패딩**

### **스트라이딩**
- 필터가 적용되는 영역을 윈도우라고 부름
- 이 윈도우는 한 픽셀 씩 움직이는 것이 아닌 두 픽셀 또는 세 픽셀 씩 성큼 성큼 움직이는 데 이 보폭을 **스트라이드**라고 부름

### **다중 채널**
- 컬러 이미지는 하나의 채널이 아니라 다수의 채널로 구성된 이미지
- 2차원 행렬 하나가 아니라 복수로 제공될 수 있음

## 6. 강건한 모델을 만드는 풀링

***

### **풀링**
- 이미지의 일정한 영역 내의 픽셀들이 가진 값을 하나로 축소하는 연산
- 합성곱과 달리 윈도우를 중첩시켜 이동시키지 않는 것이 일반적
- 풀링은 값을 어떻게 결정하느냐에 따라 최대값 풀링(max pooling), 평균값 풀링(mean pooling) 등이 있음
- 최대값 풀링은 풀링 적용 영역 내에서 가장 큰 값을 결과로 선택하는 것이고, 평균값 풀링은 평균을 구해 결과로 삼는 것
- 풀링을 사용하면 이미지의 크기가 줄어들지만 합성곱 연산을 패딩 없이 적용했을 때 이미지가 줄어드는 것과는 다르다.
> 합성곱 연산에 의한 축소는 이미지의 주변부 정보를 잃는 일이지만, 풀링은 **다수의 픽셀 정보를 통합하여 하나로 만드는 것**으로 원래 신호에 존재하는 **잡음 요소를 제거하는 일**
- 풀링은 최대값 추출이나 평균값 추출과 같이 **미리 정해진 기능을 수행하므로 학습 단계에서 파라미터를 최적화할 필요가 없는 계층**
> 원래 이미지가 가지고 있던 채널을 그대로 유지하면서 **공간만 줄이는 일을 수행**
- 다수의 픽셀 정보를 통합하여 하나의 픽셀을 생성하기 때문에 정보를 요약할 수 있으며 이 과정에서 **입력의 변화에 대해 덜 민감한 신호 전달을 달성**
- 픽셀의 값을 일부 변경하여도 **최대값 풀링의 결과는 잘 바뀌지 않음**
> **이동 불변성(translation invariance)**이라하며, 이동 불변성을 가진 모델을 **강건한(robust)모델**이라고 함

### 정리
- 인공 신경망 계층에서 **합성곱 연산을 수행하는 계층**을 합성곱 신경망
- **풀링 연산을 수행하는 계층**을 풀링 계층
- 두 종류의 계층을 통해 모델 파라미터 개수를 효율적으로 줄여주며 전체 모델 복잡도가 감소하는 효과
- 합성곱 신경망은 이 두 종류의 계층을 쌓아 나가는 형태로 인공 신경망을 구성


## 7. 합성곱 신경망 모델의 구성

***

- 합성곱 신경망의 신호 연결
> 패딩을 고려한 합성곱과 풀링이 순차적으로 이루어지게 하는 것
- 합성곱 필터의 가중치
> 파라미터로 사용되는 것
- 특징
> 몇 차례의 합성곱을 한 뒤에 풀링을 할 수도 있고 풀링 없이 합성곱으로만 연결 가능
> 풀링만으로 연결될 수는 없는데 풀링은 정보를 줄이기만 할 뿐 학습 가능한 파라미터가 없기 때문
- 이미지를 처리하기 위해 풀링과 합성곱 계층을 거져 얻은 최종 이미지를 다층 퍼셉트론(MLP)형태의 전통적인 신경망에 연결
- 이를 위해 합성곱 신경망의 앞 부분에서 얻은 이미지 정보들을 1차원 벡터로 만드는 평탄화(flatten) 과정 필요

## 8. 합성곱 신경망 모델의 성공

***



## 9. 전이학습 - 이미 훈련된 모델을 고쳐 쓰기

***
